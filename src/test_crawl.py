"""
Quick test script for TopCV crawler
Run: python test_crawl.py
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_connection():
    """Test 1: Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn TopCV"""
    print("=" * 50)
    print("üß™ Test 1: Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn TopCV")
    print("=" * 50)
    
    from scrape_topcv import build_session, BASE
    import requests
    
    session = build_session()
    
    try:
        r = session.get(BASE, timeout=30)
        print(f"   Status code: {r.status_code}")
        
        if r.status_code == 200:
            print(f"‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!")
            return True, session
        elif r.status_code == 403:
            print("‚ùå B·ªã ch·∫∑n (403 Forbidden)")
            return False, None
        else:
            print(f"‚ùå L·ªói: {r.status_code}")
            return False, None
    except Exception as e:
        print(f"‚ùå Exception: {e}")
        return False, None


def test_search_page_html(session):
    """Test 2: Ki·ªÉm tra HTML c·ªßa trang t√¨m ki·∫øm"""
    print("\n" + "=" * 50)
    print("üß™ Test 2: Ki·ªÉm tra HTML trang t√¨m ki·∫øm")
    print("=" * 50)
    
    from scrape_topcv import get_soup, slugify
    
    keyword = "Data Analyst"
    slug = slugify(keyword)
    url = f"https://www.topcv.vn/tim-viec-lam-{slug}?page=1"
    
    print(f"   URL: {url}")
    
    soup = get_soup(session, url)
    
    # Ki·ªÉm tra c√≥ n·ªôi dung kh√¥ng
    if not soup or not soup.text.strip():
        print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c HTML")
        return False
    
    print(f"   HTML length: {len(soup.text)} chars")
    
    # Ki·ªÉm tra c√°c selector c√≥ th·ªÉ d√πng
    selectors_to_check = [
        "div.job-item-search-result",
        "div.job-item",
        "div[class*='job']",
        "div.job-list",
        "div.job-listing",
        "article.job",
        "div.job-item-2",
        "div.job-item-default",
    ]
    
    print("\n   Ki·ªÉm tra c√°c CSS selectors:")
    found_selector = None
    for sel in selectors_to_check:
        elements = soup.select(sel)
        count = len(elements)
        status = "‚úÖ" if count > 0 else "‚ùå"
        print(f"   {status} '{sel}': {count} elements")
        if count > 0 and found_selector is None:
            found_selector = sel
    
    # L∆∞u HTML ƒë·ªÉ debug
    debug_file = Path("data/debug_search_page.html")
    debug_file.parent.mkdir(exist_ok=True)
    debug_file.write_text(soup.prettify()[:50000], encoding="utf-8")
    print(f"\n   üíæ Saved HTML to: {debug_file}")
    
    return found_selector is not None


def test_find_jobs(session):
    """Test 3: T√¨m c·∫•u tr√∫c job th·ª±c t·∫ø"""
    print("\n" + "=" * 50)
    print("üß™ Test 3: Ph√¢n t√≠ch c·∫•u tr√∫c trang")
    print("=" * 50)
    
    from scrape_topcv import get_soup, slugify
    from bs4 import BeautifulSoup
    
    keyword = "Data Analyst"
    slug = slugify(keyword)
    url = f"https://www.topcv.vn/tim-viec-lam-{slug}?page=1"
    
    soup = get_soup(session, url)
    
    # T√¨m t·∫•t c·∫£ c√°c th·∫ª c√≥ ch·ª©a "job" trong class
    job_elements = []
    for tag in soup.find_all(True):
        classes = tag.get("class", [])
        if any("job" in c.lower() for c in classes):
            job_elements.append((tag.name, classes))
    
    print(f"   T√¨m th·∫•y {len(job_elements)} elements c√≥ 'job' trong class:")
    
    # ƒê·∫øm v√† hi·ªÉn th·ªã unique classes
    from collections import Counter
    class_counter = Counter()
    for tag_name, classes in job_elements:
        for c in classes:
            if "job" in c.lower():
                class_counter[f"{tag_name}.{c}"] += 1
    
    for selector, count in class_counter.most_common(10):
        print(f"      - {selector}: {count}")
    
    # T√¨m c√°c link job
    job_links = soup.select("a[href*='/viec-lam/']")
    print(f"\n   T√¨m th·∫•y {len(job_links)} links ƒë·∫øn trang job detail")
    
    if job_links:
        print("   V√≠ d·ª• 3 links ƒë·∫ßu:")
        for link in job_links[:3]:
            href = link.get("href", "")
            title = link.get_text(strip=True)[:50]
            print(f"      - {title}... ‚Üí {href[:60]}...")
        return True
    
    return False


def test_parse_with_new_selector(session):
    """Test 4: Th·ª≠ parse v·ªõi selector m·ªõi"""
    print("\n" + "=" * 50)
    print("üß™ Test 4: Parse jobs v·ªõi selector kh√°c")
    print("=" * 50)
    
    from scrape_topcv import get_soup, slugify, text
    from urllib.parse import urljoin
    
    BASE = "https://www.topcv.vn"
    keyword = "Data Analyst"
    slug = slugify(keyword)
    url = f"https://www.topcv.vn/tim-viec-lam-{slug}?page=1"
    
    soup = get_soup(session, url)
    jobs = []
    
    # Th·ª≠ nhi·ªÅu selector kh√°c nhau
    selectors = [
        "div.job-item-search-result",
        "div.job-item-2",
        "div.job-item-default", 
        "div.job-item",
        "div.job-list-item",
        "div[data-job-id]",
        "article.job-item",
    ]
    
    for selector in selectors:
        job_cards = soup.select(selector)
        if job_cards:
            print(f"   ‚úÖ Selector '{selector}' t√¨m th·∫•y {len(job_cards)} jobs")
            
            # Parse job ƒë·∫ßu ti√™n
            job = job_cards[0]
            
            # T√¨m title
            title_el = job.select_one("h3 a, h2 a, .title a, a.job-title, [class*='title'] a")
            title = text(title_el) if title_el else "N/A"
            href = title_el.get("href") if title_el else "N/A"
            
            # T√¨m company
            company_el = job.select_one("a.company, .company-name, [class*='company'] a")
            company = text(company_el) if company_el else "N/A"
            
            # T√¨m salary
            salary_el = job.select_one(".salary, .title-salary, [class*='salary']")
            salary = text(salary_el) if salary_el else "N/A"
            
            print(f"      Title: {title[:50]}...")
            print(f"      Company: {company}")
            print(f"      Salary: {salary}")
            print(f"      URL: {href}")
            
            jobs.append({
                "selector": selector,
                "title": title,
                "company": company,
                "salary": salary,
                "url": href
            })
            break
    
    if not jobs:
        print("   ‚ùå Kh√¥ng t√¨m ƒë∆∞·ª£c selector n√†o ho·∫°t ƒë·ªông")
        return False
    
    return True


def main():
    print("\n" + "=" * 60)
    print("üï∑Ô∏è  TopCV Crawler - Debug & Test Script")
    print("=" * 60)
    
    # Test 1: Connection
    success, session = test_connection()
    if not success:
        print("\n‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi. Ki·ªÉm tra l·∫°i network ho·∫∑c TopCV ƒëang ch·∫∑n.")
        return 1
    
    # Test 2: HTML
    test_search_page_html(session)
    
    # Test 3: Find structure
    test_find_jobs(session)
    
    # Test 4: Parse
    test_parse_with_new_selector(session)
    
    print("\n" + "=" * 60)
    print("üìã Ki·ªÉm tra file debug: data/debug_search_page.html")
    print("   M·ªü file n√†y trong browser ƒë·ªÉ xem c·∫•u tr√∫c HTML th·ª±c t·∫ø")
    print("=" * 60)
    
    return 0


if __name__ == "__main__":
    sys.exit(main())